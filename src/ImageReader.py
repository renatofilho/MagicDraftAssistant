from PIL import Image
import pytesseract
import cv2 as cv
import numpy as np
import re
import tempfile
import os

from PySide6.QtCore import QObject, Signal, QFile, QThread, QRect
from Database import CardDB
from Calibrations import CalibrationList

# we do OCR on thread since this could block UI
class TextExtractTask(QThread):
    progress = Signal(float)

    def __init__(self, card_set, img, calibration, parent = None):
        super().__init__(parent)
        self._source_img = img
        self._result = []
        self._card_set = card_set
        self._calibration = CalibrationList.findCalibrationForImage(img)


    def _applyFilters(self, img):
        kernel = np.ones((6,6),np.uint8)
        return cv.erode(img, kernel, iterations = 1)


    def _extractText(self, img, idx):
        # write image on disk
        temp_file = os.path.join(tempfile.gettempdir(), f"text{idx}.png")
        cv.imwrite(temp_file,img)

        img = Image.open(temp_file)
        custom_config = r'--oem 3 --psm 7'
        txt = pytesseract.image_to_string(img, config=custom_config)

        # remove some garbage that could be generated by mana symbols or card borders
        txt = "".join([x for x in txt if x.isprintable()]).strip()
        txt = re.sub(r'[§)(\@‘\d{|:]', ' ', txt).strip()

        words = list(filter(None, txt.split(' ')))
        if not words:
            return ""

        # in some cases it could produce invalid words at beggining and the end
        # so we remove any word with less than 3 letters from begginin or the end
        if len(words[0]) < 3:
            words = words[1:]

        while(words):
            if len(words[-1]) < 3:
                words = words[0:-1]
            else:
                break
        return " ".join(words).strip()


    def run(self):
        # if we have a pre-calibration file we use that instead
        if self._calibration:
            self._runWithCalibration()
            return

        # this can be fine tunning to help skip some garbage in the image
        #DraftMancer
        ##################
        #LEFT_MARGIN = 10
        #RIGHT_MARGIN = 50
        #TOP_MARGIN = 0
        #BOTTOM_MARGIN = 0

        #MTGA
        ##################
        LEFT_MARGIN = 2
        RIGHT_MARGIN = 50
        TOP_MARGIN = 0
        BOTTOM_MARGIN = 0

        # Code bellow will try to find the card title area using Open CV, functions
        # It will apply some transformations and try to detect the contours of the header

        #img = self._applyFilters(self._source_img) #This is not helping, need more tests
        _, threshold = cv.threshold(self._source_img, 150, 255, cv.THRESH_BINARY)
        contours, _ = cv.findContours(threshold, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)

        self._result = []

        def _rectIsValid(width, height):
            if width < ImageReader.MIN_WIDTH:
                return False
            if height < ImageReader.MIN_HEIGHT:
                return False
            if height > ImageReader.MAX_HEIGHT:
                return False
            if height > width:
                return False

            return True

        # keep track of the progress
        p = 0.0
        max_p = len(contours)

        for contour in contours:
            p = p + 1.0
            self.progress.emit(p/max_p)

            if self.isInterruptionRequested():
                return

            rect = cv.minAreaRect(contour)
            (height, width) = rect[1]
            if not _rectIsValid(width, height):
                continue

            box = cv.boxPoints(rect)
            box = np.int0(box)

            (x, y) = box[0]
            x1 = box[1][0]
            y1 = box[2][1]

            i = len(self._result)
            texts = []
            for transform in [self._transformation1, self._transformation2]:
                rectX = x + LEFT_MARGIN
                rectX1 = (x1 - x) - RIGHT_MARGIN
                rect = QRect(rectX, y + TOP_MARGIN, rectX1, y1 - y + BOTTOM_MARGIN)

                if rect.width() < 0 or rect.height() < 0:
                    continue

                crop_img = self._source_img[y - TOP_MARGIN : y1 + BOTTOM_MARGIN, x + LEFT_MARGIN : x1 - RIGHT_MARGIN]
                txt = self._extractText(crop_img, i)
                if txt:
                    texts.append(txt)

                    self._result.append(ImageArea(rect, texts))

                    if self.isInterruptionRequested():
                        return

    # use orignal function
    def _transformation1(self, img):
        return img

    # apply some blur on the image
    def _transformation2(self, img):
        _, result = cv.threshold(img, 100, 255, cv.THRESH_BINARY)
        return result

    # if we have a calibration we use pre-defined areas to extract the title
    # this is the safest way, but only works for the pre-defined image sizes
    # check Calibrations.py for details how to add new calibrations
    def _runWithCalibration(self):
        p = 0
        rects = self._calibration.allRects()
        max_p = len(rects)
        img = self._source_img

        for rect in rects:
            texts = []
            for transform in [self._transformation1, self._transformation2]:
                img = transform(self._source_img)
                crop_img = img[rect.top():rect.bottom(), rect.left():rect.right()]
                txt = self._extractText(crop_img, p)
                if txt:
                    texts.append(txt)

            self._result.append(ImageArea(rect, texts))

            p = p +1
            self.progress.emit(p/max_p)


class ImageArea(object):
    def __init__(self, rect, texts):
        self._rect = rect
        self._texts = texts
        self._card = None


class ImageReader(QObject):
    MAX_VERTICES = 50
    MIN_WIDTH = 100
    MIN_HEIGHT = 5
    MAX_HEIGHT = 50
    LEFT_MARGIN = 0
    RIGHT_MARGIN = 45
    
    started = Signal()
    finished = Signal()
    progress = Signal(float)

    def __init__(self, db, parent = None):
        super().__init__(parent)
        self._data = []
        self._db = db
        self._current_thread = None
        self._calibration = []


    def reload(self, card_set, filename):
        self.started.emit()
        self.progress.emit(0.0)

        if QFile.exists(filename):
            self._rgb = cv.imread(filename)
            self._gray = cv.cvtColor(self._rgb, cv.COLOR_BGR2GRAY)
        else:
            print(f"Source image does not exists: {filename}")

        if self._current_thread:
            self._current_thread.requestInterruption()
            self._current_thread.wait()
            del self._current_thread

        self._current_thread = TextExtractTask(card_set, self._gray, self)
        self._current_thread.progress.connect(self.progress)
        self._current_thread.finished.connect(self._onThreadFinished)
        self._current_thread.start()


    def _onThreadFinished(self):
        card_db = CardDB(self._db)
        card_set = self._current_thread._card_set
        for data in self._current_thread._result:
            for text in data._texts:
                data._card = self._findCard(card_db, card_set, text)
                if data._card:
                    break

        self._data = self._current_thread._result
        self.progress.emit(1.0)
        self.finished.emit()


    def _findCard(self, card_db, card_set, name):
        if not name:
            return None
        if len(name) < 5:
            return None
        card_name = name.replace("’", "'")
        row = card_db.select("set_ = ? AND name LIKE ?", (card_set, f"%{card_name}%"))
        if not row:
            return None

        return row[0]


    def writeOutputImage(self, outputFileName):
        output_image = self._rgb.copy()
        found = 0
        notFound = 0

        for data in self._data:
            if not data._card:
                continue

            card_name = data._card.get('name').value()
            print("Text: [{}] Uri: [{}]".format(card_name, data._card.get('scryfall_uri', '')))
            cv.rectangle(output_image, (data._rect.left(), data._rect.top()),  (data._rect.right(), data._rect.bottom()), (0,255,0), 2)
            cv.putText(output_image, '{}'.format(card_name), (data._rect.left(), data._rect.top()), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            found = found + 1
            
        print("Total found:", found)

        print("Not found:")
        for data in self._data:
            if not data._card:
                print("Text: [{}]".format(",".join(data._texts)))

                notFound += notFound + 1
                cv.rectangle(output_image, (data._rect.left(), data._rect.top()),  (data._rect.right(), data._rect.bottom()), (0,0,255), 2)

        cv.imwrite(outputFileName, output_image)


    def cardsId(self):
        ids = []
        for data in self._data:
            if data._card:
                ids.append(data._card["id"].value())

        return ids
